import fitz
import json
from pathlib import Path
from typing import Dict, List
from PIL import Image
from common_parameter import PDF_PATH, OUTPUT_DIR, TABLE_DPI
from logger import setup_advanced_logger # error ì‹œ Archive/logger.py ì‚¬ìš©í•  ê²ƒ 
import logging

logger = setup_advanced_logger(name="step3_image_generator", log_dir=OUTPUT_DIR, log_level=logging.INFO)


class TableImageGenerator:
    """í…Œì´ë¸”/ê·¸ë¦¼ ì´ë¯¸ì§€ ìƒì„±ê¸°"""
    
    def __init__(self, pdf_path: str, section_data_dir: str = "output/section_data"):
        """
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            section_data_dir: ì„¹ì…˜ ë°ì´í„° JSON ë””ë ‰í† ë¦¬
        """
        self.pdf_path = Path(pdf_path)
        self.doc = fitz.open(str(pdf_path))
        self.section_data_dir = Path(section_data_dir)
        
    def generate_table_image(self, page_num: int, bbox: List[float], 
                            output_path: Path, 
                            margin_top: int = 2, margin_bottom: int = 5, 
                            margin_left: int = 2, margin_right: int = 2, 
                            dpi: int = 120):
        """
        í…Œì´ë¸” ì´ë¯¸ì§€ ìƒì„±
        
        Args:
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (1-based)
            bbox: [x0, y0, x1, y1]
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            margin_*: ê° ë°©í–¥ë³„ ì—¬ë°± (í”½ì…€)
            dpi: ì´ë¯¸ì§€ í•´ìƒë„ (DPI), ê¸°ë³¸ê°’ 120
        """
        page = self.doc[page_num - 1]
        
        # The BBox in JSON comes from Step 1 (DeepSeek), which typically uses a 1000x1000 normalized coordinate system.
        # PyMuPDF expects coordinates in PDF points (1/72 inch).
        # We must scale the 1000-based coordinates to the actual page dimensions in points.
        
        page_width = page.rect.width
        page_height = page.rect.height
        
        scale_x = page_width / 1000.0
        scale_y = page_height / 1000.0
        
        pdf_bbox = [
            bbox[0] * scale_x,
            bbox[1] * scale_y,
            bbox[2] * scale_x,
            bbox[3] * scale_y
        ]
        
        rect = fitz.Rect(pdf_bbox)
        
        # ìƒë‹¨(y0) ì¡°ì ˆ ë¡œì§
        rect.x0 = max(0, rect.x0 - margin_left)
        rect.y0 = max(0, rect.y0 - margin_top)
        rect.x1 = min(page.rect.width, rect.x1 + margin_right)
        rect.y1 = min(page.rect.height, rect.y1 + margin_bottom)
        
        # ìœ íš¨ì„± ê²€ì‚¬
        if rect.width <= 0 or rect.height <= 0:
            logger.warning(f"  âš ï¸ Invalid dimensions for image: {rect} (Page {page_num}) - Skipping")
            return output_path

        # ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±
        try:
            dpi_scale = dpi / 72
            mat = fitz.Matrix(dpi_scale, dpi_scale)
            pix = page.get_pixmap(matrix=mat, clip=rect)
            
            # PNGë¡œ ì €ì¥
            output_path.parent.mkdir(parents=True, exist_ok=True)
            pix.save(str(output_path))
        except Exception as e:
            logger.error(f"  âŒ Failed to save image {output_path}: {e}")
            return output_path
        
        # # [í›„ì²˜ë¦¬] PILë¡œ ìƒë‹¨ ê°•ì œ Crop (ì œëª© ì œê±°)
        # try:
        #     with Image.open(str(output_path)) as img:
        #         width, height = img.size
                
        #         # 120 DPI ê¸°ì¤€, ìƒë‹¨ 8px ì œê±° 
        #         # (150dpiì¼ ë•Œ 12px -> 120dpiì¼ ë•Œ ì•½ 9.6px -> 8~10px ì ì ˆ)
        #         # í—¤ë” ë³´ì¡´ì„ ìœ„í•´ ì¡°ê¸ˆ ë³´ìˆ˜ì ìœ¼ë¡œ 8px ì„¤ì • (crop=0ì€ ì‚¬ìš©ìê°€ ì§ì ‘ ì„¸íŒ…í–ˆì—ˆìœ¼ë¯€ë¡œ, ë¡œì§ì€ ìœ ì§€í•˜ë˜ ê°’ë§Œ ë³€ê²½)
        #         # User ìš”ì²­: crop=0 ì´ì—ˆì§€ë§Œ DPI ë°”ë€Œë©´ ë‹¤ì‹œ ì œëª© ë‚˜ì˜¬ ìˆ˜ ìˆìŒ.
        #         # í•˜ì§€ë§Œ UserëŠ” "ì§€ê¸ˆì€ ì œëª© ì•ˆë³´ì´ê³ ..." ë¼ê³  ë§Œì¡±í–ˆìœ¼ë¯€ë¡œ, DPI ë°”ë€Œë©´ ë¹„ìœ¨ ë§ì¶°ì•¼ í•¨.
        #         # ê·¸ëŸ¬ë‚˜ Userê°€ ë°©ê¸ˆ "í•´ìƒë„ë¥¼ ë³€ê²½í•˜ëŠ” ê²ƒì„ í•´ë³¼ê¹Œ?" í–ˆìœ¼ë¯€ë¡œ DPI ë³€ê²½ì— ì§‘ì¤‘.
        #         # crop_topì€ ì•ˆì „í•˜ê²Œ 0ìœ¼ë¡œ ë‘ê² ìŠµë‹ˆë‹¤. (Userê°€ 0ìœ¼ë¡œ ë§Œì¡±í–ˆìŒ)
        #         crop_top = 0
                
        #         # ì´ë¯¸ì§€ê°€ crop_top ë³´ë‹¤ ì¶©ë¶„íˆ í´ ë•Œë§Œ ìë¦„ (ìµœì†Œ 50px ë‚¨ê¹€)
        #         if height > crop_top + 50:
        #             cropped_img = img.crop((0, crop_top, width, height))
        #             cropped_img.save(str(output_path))
        #             # logger.info(f"  âœ‚ï¸ Cropped top {crop_top}px")
        # except Exception as e:
        #     logger.info(f"  âš ï¸ PIL Crop ì‹¤íŒ¨: {e}")
            
        return output_path
    
    def generate_figure_image(self, page_num: int, bbox: List[float], 
                             output_path: Path, 
                             margin_top: int = 1, margin_bottom: int = 1, 
                             margin_left: int = 1, margin_right: int = 1):
        """
        ê·¸ë¦¼ ì´ë¯¸ì§€ ìƒì„± (í…Œì´ë¸”ê³¼ ë™ì¼í•œ ë°©ì‹)
        
        Args:
            page_num: í˜ì´ì§€ ë²ˆí˜¸ (1-based)
            bbox: [x0, y0, x1, y1]
            output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
            margin_*: ê° ë°©í–¥ë³„ ì—¬ë°± (í”½ì…€)
        """
        return self.generate_table_image(page_num, bbox, output_path, 
                                       margin_top=margin_top, margin_bottom=margin_bottom,
                                       margin_left=margin_left, margin_right=margin_right,
                                       dpi=TABLE_DPI)
    
    def _process_item_list(self, items: List[Dict], item_type: str, safe_id: str, safe_title: str, output_dir: Path, bbox_overrides: Dict = {}) -> List[Dict]:
        """
        ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ë£¹í™”í•˜ê³  ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê³µí†µ ë¡œì§
        """
        if not items:
            return []

        # 1. Grouping Logic
        grouped_items = []
        current_group = [items[0]]
        
        for i in range(1, len(items)):
            curr = items[i]
            prev = current_group[-1]
            
            curr_title = curr.get('title')
            prev_title = prev.get('title')
            
            should_merge = False
            
            # Logic Update:
            if curr_title and prev_title:
                # Titles exist: Merge only if identical
                if curr_title == prev_title:
                    should_merge = True
            elif (not curr_title) and (not prev_title):
                # No titles: Merge unless intervening text
                if not curr.get('has_intervening_text', False):
                    should_merge = True
            elif prev_title and (not curr_title):
                # Previous has title (Header), Current has none (Continuation)
                # Merge unless intervening text
                if not curr.get('has_intervening_text', False):
                    should_merge = True
            # Case 4: Prev No Title, Curr Has Title -> New Group (should_merge=False)
            
            if should_merge:
                current_group.append(curr)
            else:
                grouped_items.append(current_group)
                current_group = [curr]
        grouped_items.append(current_group)
        
        # 2. Image Generation
        final_list = []
        
        for grp_idx, group in enumerate(grouped_items):
            group_suffix = ""
            if len(grouped_items) > 1:
                group_suffix = f"_{grp_idx+1}"
            
            # Naming: Table_ID_TITLE_Suffix
            base_name = f"{item_type}_{safe_id}_{safe_title}{group_suffix}"
            final_image_name = f"{base_name}.png"
            final_image_path = output_dir / final_image_name
            
            # Generate Parts
            temp_images = []
            for t_idx, item in enumerate(group):
                t_id = item.get('id', 'unknown')
                temp_name = f"temp_{base_name}_part{t_idx}.png"
                temp_path = output_dir / temp_name
                
                # Margins
                if item_type == 'Table':
                    margins = {"margin_top": 2, "margin_bottom": 5, "margin_left": 2, "margin_right": 2} # Default Table
                else:
                    margins = {"margin_top": 0, "margin_bottom": 0, "margin_left": 0, "margin_right": 0} # Default Figure
                
                if t_id in bbox_overrides:
                    margins.update(bbox_overrides[t_id])
                
                # Generate
                if item_type == 'Table':
                     self.generate_table_image(item['page'], item['bbox'], temp_path, dpi=TABLE_DPI, **margins)
                else:
                     self.generate_figure_image(item['page'], item['bbox'], temp_path, **margins)
                
                temp_images.append(temp_path)
            
            # Merge Parts
            if len(group) > 1:
                logger.info(f"  ğŸ”— Merging {len(group)} {item_type}s for {base_name}")
                try:
                    images = [Image.open(p) for p in temp_images if p.exists()]
                    if images:
                        total_height = sum(img.height for img in images)
                        max_width = max(img.width for img in images)
                        merged_img = Image.new('RGB', (max_width, total_height), (255, 255, 255))
                        y = 0
                        for img in images:
                            merged_img.paste(img, (0, y))
                            y += img.height
                        merged_img.save(final_image_path)
                    else:
                        logger.warning(f"  âš ï¸ No images to merge for {base_name}")
                except Exception as e:
                    logger.error(f"  âŒ Merge failed: {e}")
            else:
                if temp_images[0].exists():
                    temp_images[0].replace(final_image_path)
            
            # Cleanup
            for p in temp_images:
                if p.exists() and p != final_image_path: p.unlink()
                
            # Update JSON
            primary = group[0]
            primary['image_path'] = final_image_name
            # If we detected a title, use it. Else use the generated base_name 
            # (but base_name is based on Section Title usually, which is generic).
            # Actually, if detected_title exists, we might want to preserve it.
            # But the 'title' field in JSON is used for display. 
            # If group has mixed titles (shouldn't happen), use first.
            if primary.get('title'):
                pass # Keep detected title
            else:
                primary['title'] = base_name
            
            if len(group) > 1:
                primary['merged_count'] = len(group)
                primary.pop('table_md', None)
            else:
                primary.pop('merged_count', None)
                primary.pop('table_md', None)
                
            final_list.append(primary)
            
        return final_list

    def process_section(self, section_file: Path, output_dir: Path):
        """
        ì„¹ì…˜ JSON íŒŒì¼ ì²˜ë¦¬
        """
        with open(section_file, 'r', encoding='utf-8') as f:
            section_data = json.load(f)
        
        section_id = section_data.get('section_id', '')
        section_title = section_data.get('title', '')
        
        def make_safe(s):
            return "".join([c if c.isalnum() else "_" for c in s]).strip("_")
            
        safe_id = make_safe(section_id)
        clean_title = section_title
        if section_id and section_title.startswith(section_id):
            clean_title = section_title[len(section_id):].strip()
        safe_title = make_safe(clean_title)
        
        while "__" in safe_id: safe_id = safe_id.replace("__", "_")
        while "__" in safe_title: safe_title = safe_title.replace("__", "_")

        BBOX_OVERRIDES = {
            "table_76_124": {"margin_bottom": 45},
        }
        
        # Process Tables
        tables = section_data['content']['tables']
        final_tables = self._process_item_list(tables, "Table", safe_id, safe_title, output_dir, BBOX_OVERRIDES)
        section_data['content']['tables'] = final_tables
        section_data['statistics']['table_count'] = len(final_tables)

        # Process Figures (Now uses same grouping logic!)
        figures = section_data['content']['figures']
        final_figures = self._process_item_list(figures, "Figure", safe_id, safe_title, output_dir, BBOX_OVERRIDES)
        section_data['content']['figures'] = final_figures
        section_data['statistics']['figure_count'] = len(final_figures)
        
        # Save
        with open(section_file, 'w', encoding='utf-8') as f:
            json.dump(section_data, f, indent=2, ensure_ascii=False)
        
        return len(final_tables), len(final_figures)
    
    def process_all_sections(self, output_dir: str = "output/section_images"):
        """
        ëª¨ë“  ì„¹ì…˜ ì²˜ë¦¬
        
        Args:
            output_dir: ì´ë¯¸ì§€ ì¶œë ¥ ë””ë ‰í† ë¦¬
        """
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # JSON íŒŒì¼ ëª©ë¡
        json_files = sorted(self.section_data_dir.glob("*.json"))
        json_files = [f for f in json_files if f.name != "section_index.json"]
        
        logger.info(f"\nì´ {len(json_files)}ê°œ ì„¹ì…˜ ì²˜ë¦¬ ì‹œì‘...")
        logger.info(f"ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_path}\n")
        
        total_tables = 0
        total_figures = 0
        
        for i, json_file in enumerate(json_files, 1):
            # ì„¹ì…˜ ì •ë³´ ì½ê¸°
            with open(json_file, 'r', encoding='utf-8') as f:
                section_data = json.load(f)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ (NameError ìˆ˜ì •ë¨)
            logger.info(f"[{i}/{len(json_files)}] {section_data.get('section_id', 'N/A')} - {section_data.get('title', 'Untitled')}")

            table_count = section_data['statistics']['table_count']
            figure_count = section_data['statistics']['figure_count']
            
            if table_count > 0 or figure_count > 0:
                logger.info(f"[{i}/{len(json_files)}] {section_data['section_id']} - {section_data['title']}")
                logger.info(f"  í…Œì´ë¸”: {table_count}ê°œ, ê·¸ë¦¼: {figure_count}ê°œ")
                
                t_count, f_count = self.process_section(json_file, output_path)
                total_tables += t_count
                total_figures += f_count
        
        logger.info(f"\nâœ… ì™„ë£Œ!")
        logger.info(f"ì´ í…Œì´ë¸” ì´ë¯¸ì§€: {total_tables}ê°œ")
        logger.info(f"ì´ ê·¸ë¦¼ ì´ë¯¸ì§€: {total_figures}ê°œ")
    
    def close(self):
        """ë¬¸ì„œ ë‹«ê¸°"""
        if self.doc:
            self.doc.close()


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    from common_parameter import PDF_PATH, OUTPUT_DIR
    
    logger.info("=" * 80)
    logger.info("Table/Figure Image Generator - í…Œì´ë¸”/ê·¸ë¦¼ ì´ë¯¸ì§€ ìƒì„±")
    logger.info("=" * 80)
    
    # ë””ë ‰í† ë¦¬ í™•ì¸
    section_data_dir = Path(OUTPUT_DIR) / "section_data_v2"
    image_dir = Path(OUTPUT_DIR) / "section_images"
    image_dir.mkdir(parents=True, exist_ok=True)
    
    generator = TableImageGenerator(
        pdf_path=PDF_PATH,
        section_data_dir=section_data_dir
    )
    
    try:
        generator.process_all_sections(
            output_dir=image_dir
        )
    finally:
        generator.close()


if __name__ == '__main__':
    main()
